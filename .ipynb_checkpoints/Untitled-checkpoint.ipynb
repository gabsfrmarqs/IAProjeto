{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3348548-8dc6-4444-b4f4-031673236572",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Média'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 79\u001b[0m\n\u001b[0;32m     75\u001b[0m model \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[0;32m     76\u001b[0m                            (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregressor\u001b[39m\u001b[38;5;124m'\u001b[39m, RandomForestRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))])\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# 7. Treinar o Modelo\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# 8. Avaliar o Modelo\u001b[39;00m\n\u001b[0;32m     83\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py:473\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    472\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 473\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    421\u001b[0m y, expanded_class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_y_class_weight(y)\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m!=\u001b[39m DOUBLE \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mcontiguous:\n\u001b[1;32m--> 424\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mascontiguousarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDOUBLE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expanded_class_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Média'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 1. Carregar o Dataset\n",
    "try:\n",
    "    df = pd.read_csv(\"Steam_2024_bestRevenue_1500.csv\")  # Nome correto do arquivo\n",
    "except FileNotFoundError:\n",
    "    print(\"Arquivo não encontrado. Certifique-se de que 'Steam_2024_bestRevenue_1500.csv' está no mesmo diretório.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "\n",
    "# 2. Limpeza e Pré-processamento\n",
    "\n",
    "# Converter 'releaseDate' para datetime e extrair o ano\n",
    "df['releaseDate'] = pd.to_datetime(df['releaseDate'], errors='coerce')\n",
    "df['Release Year'] = df['releaseDate'].dt.year\n",
    "\n",
    "# Converter publisherClass para string\n",
    "df['publisherClass'] = df['publisherClass'].astype(str)\n",
    "\n",
    "# Selecionar colunas relevantes e criar/transformar features\n",
    "df = df[['name', 'revenue', 'price', 'copiesSold', 'avgPlaytime', 'reviewScore', 'publisherClass','Release Year']] # 'steamId' pode ser útil como ID, mas não como feature\n",
    "df.rename(columns={'revenue': 'Revenue'}, inplace=True) # Padronizar nome da coluna alvo\n",
    "\n",
    "# Criar categorias de receita (exemplo)\n",
    "df['Revenue_Category'] = pd.qcut(df['Revenue'], q=3, labels=['Baixa', 'Média', 'Alta']) # Divide em 3 categorias com base nos quartis\n",
    "\n",
    "# 3. Tratar valores faltantes (imputação com a mediana para numéricas, mais frequente para categóricas)\n",
    "\n",
    "numerical_features = ['price', 'copiesSold', 'avgPlaytime', 'reviewScore', 'Release Year']\n",
    "categorical_features = ['publisherClass']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# 4. Dividir em Treino e Teste (antes do pré-processamento final)\n",
    "X = df.drop(['Revenue', 'Revenue_Category'], axis=1)  # Remove ambas as colunas de receita\n",
    "y = df['Revenue_Category'] # Define 'Revenue_Category' como alvo (y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Armazenar os nomes dos jogos ANTES do pré-processamento\n",
    "X_train_names = X_train['name']\n",
    "X_test_names = X_test['name']\n",
    "\n",
    "# Remover a coluna 'name' do X_train e X_test para o treinamento do modelo\n",
    "X_train = X_train.drop('name', axis=1)\n",
    "X_test = X_test.drop('name', axis=1)\n",
    "\n",
    "\n",
    "# 5. Pré-processamento com ColumnTransformer (após a divisão treino/teste)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# 6. Pipeline do Modelo\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', RandomForestRegressor(random_state=42))])\n",
    "\n",
    "# 7. Treinar o Modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 8. Avaliar o Modelo\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular a matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_pred, labels=['Baixa', 'Média', 'Alta'])\n",
    "\n",
    "# Imprimir a matriz de confusão\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f46027-8c45-42a8-9ec5-cf805b048e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DataFrames com as previsões e os nomes dos jogos para o conjunto de teste\n",
    "test_comparison = pd.DataFrame({'name': X_test_names, 'Real': y_test, 'Previsto': y_pred})\n",
    "test_comparison = pd.merge(test_comparison, X_test, on=X_test.index).drop(columns=['key_0']).reset_index(drop=True) # Usar .index como chave\n",
    "\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "# Criar DataFrames com as previsões e os nomes dos jogos para o conjunto de treino\n",
    "train_comparison = pd.DataFrame({'name': X_train_names, 'Real': y_train, 'Previsto': y_train_pred})\n",
    "train_comparison = pd.merge(train_comparison, X_train, on=X_train.index).drop(columns=['key_0']).reset_index(drop=True)  # Usar .index como chave\n",
    "\n",
    "\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28867a32-4be6-4e65-84d6-af779276fd54",
   "metadata": {},
   "source": [
    "RMSE: 1177379.5072550725\n",
    "R-squared: 0.9973243302364824"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723c0d7b-d7f3-4e71-85e1-33f98ec85048",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDados de Treino (Amostra):\")\n",
    "print(train_comparison.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e75a46-0067-4f1c-8e4a-ce949917538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDados de Teste (Amostra):\")\n",
    "print(test_comparison.sample(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
